[intro_sound] Hello and welcome! My name is william, today we're going to tackle Dijkstra's shortest path algorithm. This is one of the most important algorithms in graph theory for finding the shortest paths, so without further ado let's dive in.

The first thing to mention about Dijkstra's algorithm is that it is a single source shortest path algorithm for graphhs with non-negative edge weighhts. Thhis means thhat at the beginning of the algorithm you need to specify a starting node to indicate a relative starting point. Once you specify the starting node Dijkstra's can tell you thhe shortest path between that node and all other nodes in the graph which is pretty sweet.
Depending on how you implement your Dijkstra's and what data structures you use the time complexity is typically  O(E*log(V)) which is competitive against other SSSP algorithms we see around.

Before we go crazy trying to find shortest pathhs on various types of graphs you need to know that Dijkstra's requires thhat all edges of our graph have a non-negative weights. This constraint is imposed to ensure that once a node has been visited its optimal distance cannot be improved by finding a shorter path by taking an edge with a negative weight.
This is property is especially important because it enables Dijkstra’s algorithm to act in a greedy manner by always selecting the next most promising node.

For this slide deck, my goal is to help you understand how to implement Dijkstra’s algorithm, and also how to implement it very efficiently.
We're going to start by looking at the naive implementation because it's by far the most common and then we'll get into using an indexed PQ alongside the decreaseKey operation; and lastly I want to briefly mention how we can use a D-ary heap to further boost performance.

At a high level we can examine the steps required in executing Dijkstra's algorithm. First we'll need two bits of information, first is an array called 'dist' that keeps track of the shortest distance to every node from the start node. Initially this array is filled with the value positive infinity except for the index of the starting node which should be initialized to zero.
Additionally we'll need to maintain a PQ of key-value pairs of (node index, distance) pairs which tell you which node to visit next based on sorted min value.
At first insert the key-value pair (s, 0) into the PQ and loop while PQ is not empty pulling out the next most promising (node index, distance) pair as we go.
For each node we visit we'll want to iterate over all the outwards edges and relax each edge appending a new (node index, distance) key-value pair to the PQ for every relaxation.
We do this until our PQ is empty at which point the shortest distance to each node is known and stored in the 'dist' array we maintain.

That explanation was a little abstract, let's have a look at the simple example with a standard PQ. In all these examples assume node 0 is the starting node.

Boxed in red is the distance array I will be using to track the optimal distance from the start node to each node in the graph. At the beginning, the distance to every node is initialized to positive infinity since we assume every node is unreachable. If at the end of the algorithm there's still a value of infinity at a certain index we know that that node is unreachable.

Then on the right I will be maintaining key-value pairs corresponding to a node's index and the best distance to get to that node. This PQ will tell us which node we should visit next based on the which key-value pair has the lowest value.

To start with, assign a distance of zero to the start node at index 0 in the distance array. Also insert the key-value pair (0, 0) into the PQ to indicate that we intend on visiting node 0 with a best distance of 0.

Then the algorithm actually starts and we look inside the PQ for the first time and we discover that we should visit node 0.

From node 0 we can visit node 1 by using the edge with a cost of 4. This gives us a best distance of 4, so we can update our best distance from infinity to 4 in the 'dist' array. Also add this information to the PQ.

Next we can visit node 2 from node 0. Just like the last node we can update the optimal distance to reach node 2 from infinity to 1. Also add that node 2 is reachable with a distance of 1 to the PQ.

That concludes visiting all the edges for node 0. To decide which node to visit next Dijkstra's always selects the next most promising node in the PQ, so we can poll which node to visit next by extracting the best key-value pair.

Node 2 is the next most promising node because it has a distance of 1 from the start node while node 1 has a greater value of 4.

From node 2, if we take the upwards edge we can improve the best distance to node 1 by taking the current best distance from node 2, which is 1, plus the edge cost of 2 to get the node 1, for a total cost of 3, which is better than the previous value of 4. Every time we find a better distance to a node we need to insert that information into the PQ.

Then we can improve the best distance to node 3 to be 6.

<press>

The next most promising node is node 1

We can improve the best distance to node 3 by taking the edge from node 1 to node 3 with a cost of 1.

<press>

<press>

The next most promising node is node 1 with value 4, but we have already found a better route to get to node 1 since the 'dist' array at index 1 has value 3, therefore we can ignore this entry in the PQ. Having these duplicate key entries in the PQ is what constitutes making this implementation of Dijkstra's lazy because we lazily delete outdated key-value pairs.

Next up is node 3

Update the best value to node 4 to be 7

<press>

We already found a better route to node 3 so skip this entry in the PQ.

Finally visit node 4

That's all there is for the lazy implementation of Dijkstra's algorithm. There are only a few moving parts, but in large the only things to keep track of is the 'dist' array which contains the best distance so far from the start node to every other node, and the PQ which tells you which node to visit next based on the best value found so far.

Let's look at some pseudo code for how this works. This implementation will run Dijkstra's algorithm from a start node and return the distance array which will tell you shortest distance to any other node. However, it will not tell you which sequence of edges to follow to achieve that optimal distance, to do that we'll need to keep track of some additional information which I'll cover soon.

In terms of the variables we'll need, in the function definition I specify three things:
The first is 'g', an adjacency list of the weighted graph,
'n', the number of nodes in the graph
and s, the index of the start node.

Inside the function the first thing I do is initialize two arrays to track some information we'll need. 
First is a boolean array called 'vis' short for visited which tracks whether or node i has been visited or not.
Then is 'dist' the distance array, which will be the output of the function. Make sure you set all the initial values for the dist array to be infinity except for the start node which should be zero.

After this initialize a PQ that will store (node index, best distance) pairs sorted by minimum distance. You should be able to use the built in PQ for whatever programming language you're using.

Remember to insert the start node's index paired with a distance of zero into the Pqto kick start the algorithm.

So while the PQ is not empty, remove the next most promising (index, min distance) pair and mark that node as visited.

Loop over all the neighbors of the current node and skip the visited neighbors because we do not want to visit them again.

Then simply perform the relaxation. First compute the distance to the new node which is the best distance from the start node to the current node which is found in the dist array plus the edge cost to get to the next node. Once you know that, compare it against the current best distance for the next node and update the value if it's better. Then finally insert a new key-value pair inside the PQ so we visit that node in the future.

So in practice most standard libraries do not support the decrease key operations on PQs. You can think of a decrease key operation as an operation which updates the value of a key in the PQ. A way to get around this is to add a new (node index, best distance) pair every time we need update the distance to a node.

As a result, it is possible to have duplicate node indices in the PQ. This is not ideal, but inserting a new key-value pair in logarithmic time is much faster than searching for the key you want to update in the PQ which takes linear time and then updating its value.

<pause><press>

A neat optimization we can do which ignores stale (index, dist) pairs in our PQ is to skip nodes where we already found a better path routing through others nodes before we got to processing this node.

Now I want to talk about actually finding the shortest path, not just the distance to get there. To do this we'll need to keep track of some additional information, in particular, we'll want to keep track of the index of the previous node we took to get to the next node.

The way to do this is to maintain a previous array which tracks the index of the node you took to get a particular node i. Initially the previous array should contain all null values, but as you are able to perform relaxation operations you want to update the previous array to say that the node you're going to came from the node you're currently at. Then at the end, instead of just returning the distance array also return the previous array which we'll need soon.

In another method, perhaps one called findShortestPath, provide all the same arguments with the addition of the end node index and execute Dijkstra's to obtain the dist and prev arrays. With these two bits of information we can reconstruct the shortest path. First, check that the end node is reachable by checking that its value in the dist array is not infinity, then starting at the end node loop backward through the previous array until you make is back to the start node. You know you have made it back to the start node when a value of null is reached since the start node doesn't have a parent node index from which it came from.
The resulting path of nodes indices to follow for the shortest path from the start node to the end node will be in reverse order because we started at the end node and worked backwards so make sure you reverse the array before returning.

Now I want to talk about a few optimization we can use to make Dijkstra's algorithm more efficient. Sometimes we know the index of our destination node and don't necessarily need to know the optimal distance to every node in the graph just that one node. So the question is do we still have to visit every node in the graph?

Actually yes we do, but only in the worst case. However, it is possible to stop early once you have finished visiting the destination node.

The main idea for stopping early is that Dijkstra’s algorithm processes each next most promising node in order. So if the destination node has been visited, its shortest distance will not change as more future nodes are visited.

So all we have to do to stop early is to check if the current index is the end node and stop the algorithm early. This can prove to be a very substantial speedup depending on how early you encounter the end node while processing the graph.

Our current implementation of Dijkstra’s is what we call the lazy implementation because it inserts duplicate key-value pairs and lazily deletes them because it’s more efficient to insert a new key-value pair in logarithmic time into the PQ than it is to update an existing key’s value in linear time.
The lazy approach works, but it is inefficient for dense graphs because we end up with several stale outdated key-value pairs in our PQ. The eager version of Dijkstra’s however avoids duplicate key-value pairs and supports efficient value updates in O(log(n)) by using an Indexed Priority Queue (IPQ).

An Indexed PQ is a PQ variant which allows access to key-value pairs within the PQ in constant time and updates in log time if you're using a binary heap. This type of PQ is extremely useful in many application and I highly recommend you watch my video on the indexed PQ. I'll make sure to leave a link in the description, but in the meantime we'll just assume we have access to an indexed PQ at hand.

Now we're going to look at the eager version of Dijkstra's algorithm where we don't ever have duplicate keys in the PQ.

First insert the index of the start node with value zero into the PQ and visit that node.

Then visit all the neighbors of zero
.........
.........
.........


So that's the eager version of Dijkstra's algorithm which I would say is the proper way of implementing Dijkstra's. Let's take a look at some pseudo-code to see what needs to change.

First notice that we're using an indexed PQ instead of a regular PQ. Also notice that we no longer need to wrap our key-value pairs as tuples in an object because indexed PQs have first class support for key-value pairs as opposed to a PQ you would find in a standard library.

The other thing that changes is how we insert key-value pairs into the PQ. If the key or node index does not yet exist in the IPQ insert it, otherwise invoke a decreaseKey operation to update the best distance to that node in the PQ. The operation is called decrease key instead of update because it only updates the value if it's strictly less than the current value in the PQ.

Alright we've looked at several Dijkstra optimizations already but there's one last one I want to talk about, and that it improving the heap we're using. Currently we're probably using an indexed binary heap but we can do better. The thing to notice is that when executing Dijkstra’s algorithm, especially on dense graphs, there are a lot more updates (i.e decreaseKey operations) to key-value pairs than there are dequeue operations.
A D-ary heap is a heap variant in which each node has at most D children instead of at most 2. This speeds up decrease key operations at the expense of more costly removals.

For example, here's a d-ary heap with D equal to 4.

In this heap suppose we want to update the node with index 6 to have a new shortest distance of 1.

What we should do is lookup the position of the node with index 6 in the heap and update its value. Then we need to adjust its position within the heap. This is a min heap so low values belong above high values. 1 is less than 3 the value of the node directly above the purple node so they should swap positions.

Similarly, a value of 2 is greater than a value of 1 so we should swap again.

Now our heap invariant is satisfied once again.

So the whole update only took two swaps in total because the heap was very flat.

In contrast let's suppose we want to remove the root node.

So the node in red is the node we want to remove and we're going to swap it with the node in the bottom right position in purple because that's our technique for removing from this type of heap.

We do the swap and now we can remove the red node.

However, the heap invariant is not satisfied at the moment because the purple node we swapped into the root's position has a greater value than some of its children. What we need to do is search the D children of the current node and find the minimum key-value pair to swap the purple node downwards.

<press>

<press>

<press>

<press>

The value of two was the smallest so we swap with that node. 

The heap invariant is still not satisfied because some of the children of the purple node have a value less than it.

<press>

<press>

<press>

<press>

After searhcing all the children we determine that the node with value 3 has the smallest value so we swap with that one.

<press>

So in conclusion, what I want to demonstrate was that decreaseKey operations are very efficient with a D-ary heap but removals can be very expensive although they are more rare. There's definitely a trade off and it depends on the density of your graph.

The question then becomes, what is the optimal D-ary heap degree I should use to maximize performance of Dijkstra's algorithm? The answer is in general a value of D equal to the number of edges divided by the number of nodes is the best degree to use to balance removals against decreaseKey operations. In turn this improves Dijkstra’s time complexity to big O of E times log base E divided by V of V which is much better especially for dense graphs which have lots of decreaseKey operations. 

That's all I have for now, thank you so much for watching! Implementation source code and slides can be found at github.com slash williamfiset slash algorithms. There should be a link in the description below. Again, thanks for watching and please give this video a thumbs up if you learned something and subscribe for more mathematics and computer science videos.

Next video we'll be looking at some source code for everything we talked about in this video see you then.

[outro sound]











