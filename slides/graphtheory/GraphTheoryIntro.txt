1) Hello and welcome, my name is William and i'm super excited [actually be excited lol] to bring to you this video series focused on graph theory. Graph theory is one of my absolute favorite topics in computer science, all the algorithms we're going to see are amazingly elegant, the whole field is one of the most applicable and useful for real world applications, and I think everyone should be able to, learn, love, enjoy and admire graph theory.
This video and the first few videos are going to be ramp up videos to introduce the topics of how we store, represent and traverse graphs on a computer. BTW, this whole series will be taking on a computer science view point of graph theory rather then a mathematical one, so we won't be covering proofs and so on per se, instead we will be looking at algorithm implementation details and code.

2) So, what is graph theory? In essence it's the study of the properties and applications of graphs which common folk refer to as networks. This is a very board topic and my goal with this video series is to teach you how to apply graph theory to real world applications.

3) Graphs can be used to represent almost any problem which makes them so interesting because they pop up everywhere. A simple problem that can be phrased as a graph theory problem might be: Given the constraints in this picture, how many different sets of cloths can I make by choosing an article from each category? Of course this could also be phrased and solved using only mathematics, but the advantage to graph theory is that it allows us to visualize the problem using nodes to represent an article of clothing and edges to represent relationships between them.

4) Another canonical graph theory example is a social network of friends. A graph representation enables us to answer interesting questions such as: how many friends does person X have? Or how many degrees of separation are there between person X and person Y?

5) Now we have to talk about types of graphs. There are many different types of graph representations and it’s important to be able to recognize what type of graph you’re working with especially when you're programming and want to solve a particular problem.

6) This first type of graph is an undirected graph, it's one where edges have no orientation. That is if there's an edge from node u to node v it is identical to the edge from node v to node u. 

7) For instance, in the following graph, nodes are cities and edges represent bidirectional roads since if you drive from one city to another you can also retrace your steps driving the other way.

8) In contrast to undirected graphs are directed graphs sometimes called digraphs. In these graphs, you've guessed it, the edges are directed. So if we have an edge from u to v then you can only go from node u to node v not the other way around.

9) In this graph you can see that the edges are directed because of the arrowheads on the edges between nodes. This graph could represent people who bought each other gifts, so an incoming edge represents receiving a gift and an outgoing edge represents giving a gift. Therefore, person E bought person D a gift, person A bought themselves and person B a gift and person F bought nobody any gifts and received none (they're probably Ebenezer scrooge).

10) So far we've only seen unweighted graphs, but edges on graph can contain certain weights to represent arbitrary values such as cost, distance quantity et certera. Weighted graphs come in both the directed and undirected flavors. As a side node, I will usually denote an edge of a graph as a triplet (u, v, w) to indicate where an edge is coming from, where it's going to and what its weight is. Of course with such a notation I will also need to specify whether the graph is directed or undirected.

11) Next up I want to talk about some special types of graphs. There are so many different types of special graphs so I only selected a handful that will be most relevant for this upcoming video series.

12) The most important type of special graph is definitely the tree. A tree is simply an undirected graph with no cycles, there are several equivalent definitions of what a tree is, another is a graph with N nodes and N-1 edges. All the graphs below are trees, yes even the leftmost one since it has no cycles.

13) A related, but totally different type of graph is a rooted tree. The distinction here is that a rooted tree has a designated root node where every edge either points away from or towards the root node. When edges point away from the root the graph is called an arborescence or an out-tree and anti-arborescence or in-tree otherwise. Out trees are by far more common than in-trees from what i've observed; it is also fairly common for people to refer to a rooted tree simply as a tree instead of an in or out tree, but there is an important difference.

14) Next up are directed acyclic graphs, these are graphs with directed edges and no cycles. These graphs are very important and fairly common in computer science since they often represent structures with dependencies such as: a scheduler, a build system, a compiler maybe or perhaps more relate-able: university class prerequisites. There are several efficient algorithms we'll be looking at that deal specifically with directed a cyclic graphs, such as how to find shortest paths and produce a topological ordering of the nodes. A topological ordering is an ordering of the nodes that tells you how to process the nodes in the graph so that you don't perform a task before first having completed all its dependencies. For example, a topological ordering of class prerequisites would tell you to take intro biology and intro chemistry before taking a class on genomics.

15) This next type of special graph is a bipartite graph, it is one whose vertices can be split into two independent groups U and V such that every edge connects between U and V. This is just a fancy way of saying that the graph is two colourable or than there are no odd length cycles. Often a problem we like to ask is what is the maximum matching we can create on the bipartite graph. Suppose white nodes are jobs and red nodes are people, then we can ask how many people can be matched to jobs? In this case there are lots of edges in each graph so I think the answer is four, but in general its not so easy if there are less edges, tougher constraints and more conflicts. Bipartite graphs also play a critical role in the field on network flow which we will talk about later.

16) This last type of graph is a complete graph. It is one where this is a unique edge between every pair of nodes in the graph. A complete graph with n vertices is denoted as the graph K sub n. I have listed K1 through 6 on the bottom and you can easly see how this scales as we add more nodes. Complete graphs are often seen as the worst case graph you can possibly encounter because of how many edges there are. So if you want to test your algorithm for performance a complete graph is an easy way to start.

# Stop vid?

17) One thing we're going to have to be really cognizant about is how we're actually representing our graphs on the computer. This isn't just what type of graph it is, but what type of data structure it our graph being represented with and this will have a huge impact on performance.

18) The simplest way is inside a 2D adjacency matrix. This idea is that the cell m i j represents the edge weight of going from node i to node j. So in the graph below there are four nodes so I create a 4 by 4 matrix and populate the graph with all the edge weights. If you look at the edge weight from node C to node D you'll see that it has an edge weight of 2 so in row 3 column 4 there a value of 2. Note that It is often assumed that the edge of going from a node to itself has a cost of zero which is why the matrix diagonal has all zero values.

19) This matrix has several advantages:
- First, it's really space efficient for dense graphs.
- Edge weight lookup is constant time which is nice.
- and lastly that I would argue this is the simplest graph representation.
On the downside however the main reason people dont go for the adjacnecy matrix as a first choice is because:
- It requires V squared space. Which is a lot of space. In practice graphs with 10000 or more nodes start to become infeasible quickly.
- The other issue with the adjacency matrix is that it requires V squared work to iterate over all the edges of your graph. This is fine for dense graphs with lots of edges but isn't great for sparse graphs since most cells will be empty.

20) The main alternative to the adjacency matrix is the adjacency list which is a way to represent a graph as a map of nodes to a list of edges. The idea is that each node tracks all of its outgoing edges.

21) For example, node C has three outgoing edges so in the map entry for C we keep track of the edge from C to A with cost 4, the edge from C to B with cost 1 and the edge from C to D with cost 2. Notice that in the list of edges we only need to track of two things: The node we're going to and the cost to get there, we don't need to keep track of where we came from because that's implicitly known.

22) The nice thing about adjacency lists is that it's great for sparse graphs because it only tracks the edges you have and doesn't allocate additional memory you might not use like an adjacency matrix. This also means it's efficient when iterative over all the edges.
The main disadvantage to using an adjacency list is that its less efficient on denser graphs. Another subtle disadvantage is that it takes big of E time to access a specific edge's weight although you rarely or ever need to do this in practice.

23) The last representation I want to talk about is the edge list. An edge list is a way to represent a graph simply as an unordered list of edges. Basically it's exactly what it sounds like: a list of edges. Assume the notation for any triplet (u,v,w) means: "the cost from node u to node v is w". So for this graph the edge list is simply a list of 6 edges represented as triplets. This representation is very simple, however it lacks structure and that's why it's seldom used.

24) Advantages to the edge list are that it's great for sparse graphs, iterating over all the edges is super easy, and the structure is simple. The downsides include the edge lookup time and memory issues on large graphs.


---------------------------------

26) Hello and welcome back, my name is William and today I want to talk about some common problems in graph theory and their solutions. A lot of problems you will encounter can often be reduced to a famous graph theory problem or a variant thereof, so it's important to familiarize ourselves with common graph theory problems.

27) Just before we get started, following off what we learned in the last video about ways of representing graphs, I want you to think about various things as i'm describing common graph theory problems to you including:
1) Is the graph in the problem i'm describing directed or undirected?
2) Are the edges of the graph weighted
3) Is the common use-case a graph that is likely to be sparse or dense with edges?
4) and lastly: should I use an adjacency matrix, adjacency list, an edge list or other structure to represent the graph efficiently? 

28) One of the most, if nott he most common problem in graph theory is the shortest path problem. Given a weighted graph, find the shortest path of edges from node A to node B. 

29) So if we pretend this graph represents a road system and we're at node A and want to get to node H then our shortest path algorithm should be able to find us a list of edges to follow that will lead us from A to H with minimal cost. Lucky for us many algorithms exist to oslve the shortest path problem including: A BFS on an unweighted graph, Dijkstras algorithms, Bellman-Ford, A* and many others.

30) As simple as it sounds, connectivity is a big issue in graph theory. The problem can be simflified to: does there exist a path from node A to node B? In this scenario I don't care about the minimum cost, we just want to know if one node can reach another node.

31) A typical solution to this is to use a union find data structure or any basic search algorithm such as a DFS or BFS.

32) Another problem is finding and detecting negative cycles in a directed graph. Sometimes we're dealing with graphs that can have negative edge weights and we need to know if a negative cycle exists because it can throw everything off if there is.

33) In this graph nodes 1,2, and 3 form a negative cycle because you can cycle through all the nodes and end up with a cost of -1. In fact, you can cycle endlessly getting smaller and smaller costs. In the context of shortest paths, negative cycles are like wells you fall into and cannot get out of so they're bad. However, there are some contexts where negative cycles are beneficial, suppose we're trading currencies across  an exchange or multiple exchanges. Currency prices try to remain consistent throughout the day across exchanges such as USD to EUROs and CANADIAN to YEN, but sometimes there are inconsistencies with currency exchange prices. This makes it possible to do something called an arbitrage, which cycles through multiple currencies exchanging one currency for another coming back to the original currency with more money then you started with at a risk free gain. This is something we can use graph theory for. There are two well known algorithms: Bellman-ford and Floyd-Warshall that do this.

34) Something else that comes up now and again is finding strongly connected components of a graph. This is analogous to finding the connected components of an undirected graph but for directed graphs. 

35) When looking for SSCs we're looking for self-contained cycles with the graph where every vertex in a given cycle can reach every other vertex in the same cycle. This is useful in many algorithms usually as an intermediate step so it's important to know how to find these strongly connected components.

36) You probably won't go through your computer science career without hearing about the TSP. The TSP problem is the problem of having n cities and the distances between each or them and finding what the shortest path that visits each city and comes back to the original city.

37) For example, if our graph is the one on the left, a possible TSP solution is the graph on the right which has a cost of 9.

38) The TSP problem is NP-Hard meaning it’s a very computationally challenging problem. This is unfortunate because the TSP has several very important applications. Some famous algorithms we can use to solve this problem include: The help-Karp algorithm with dynamic programming, branch and bound and many many approximation algorithms including the any colony optimization.

39) Bridges in graphs are something of a fascination to me. They are edges which if removed increase the number of connected components of the graph.

40) In this graph the edges highlighted in pink are the bridges. Bridges are important in graph theory because they often hint at weak points, bottlenecks or vulnerabilities in a graph. Think of your graph as a telephone network, a physical set bridges between islands or other and you can immediately see the usefulness of detecting bridges.

41) Related to bridges but not the same are articulation points which are nodes that if removed increase the number of connected components of a graph.

42) In the same graph you see here there are three articulation points highlighted in pink.

43) This next problem is finding the minimum spanning tree of a graph. A minimum spanning tree is a subset of the edges of a connected, edge-weighted graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight. For example, in the graph below one possible MST is

44) this graph with a least cost of 12. Note that MSTs all have the same minimum cost but are not unique.

45) MST are seen in lots of different applications in computer science including: Designing a least cost network, circuit design, transportation networks, and etc… They're also used in multiple approximation algorithms. If you want to find the MST of a graph I recommend using one of Kruskal's, Prims or Boruvka's algorithm.

46) This last problem I think is the most fascinating, and it is about finding the maximum flow through a special type of network called a flow network. Flow networks are networks where edge weights represent capacities in a why. Capacities might be things like the maximum amount of cars on a road, the maximum amount of volume of water that can flow through a pipe, or even how many people can comfortably walk through a hallway. 
In these types of flow-networks we often want to ask ourselves the question: "With an infinite input source, that is of cars, water, people, whatever, how much “flow” can we push through the network? Assuming that we start at some source and try to make it to a sink node. This question is important because at some point there is bound to be a bottleneck somewhere in our flow graph that limits the amount of stuff we can have traveling on the network. The maximum flow would then represent things like: the volume of water allowed to flow through a network of pipes, the number of cars the roads can sustain in traffic or the maximum amount of people that can navigate through the hallways going from one class to another.
With these maximum flow problems we can identify bottlenecks that slow down the whole network and fix the edges at need to have a higher capacity.


47) That's all the problems I wanted to talk about today. Cheers everybody and next video I think i'll be talking about the DFS algorithm, stayed tuned and subscribe for more mathematics and computer science videos.

--------------------------------------------------------------------

48) Hello and welcome! My name and William and today we're moving on to talking about the DFS algorithm which plays a central role in several graph theory algorithms.

49) So what is a DFS? A DFS is a core algorithm in graph theory that allows you to explore nodes and edges of a graph, so it's a form of traversal algorithm. The nice thing about a DFS is that it's really easy to code and it runs in a time complexity of big O of V plus E which is directly proportional to the size of your graph.
By itself the DFS isn’t all that useful, but when augmented to perform other tasks such as count connected components, determine connectivity, or find bridges/articulation points DFS really shines.

50) Let's look at an example; as the name suggests a DFS plunges depth first into a graph without regard for which edge it selects next until it cannot go any further at which point it backtracks and continues.

... 

103) So let's look at some pseudo code for a DFS to get a deeper understanding for how it works.

104) The first thing we'll need are three variables:
- n, the number of nodes in our graph
- g, the adjacency list representing the graph
- and visited, a boolean array contained true or false at index i depending on whether or not node i has been visited. In the beginning this array should have all false values because we have not visited any nodes in the graph.

105) Once that's setup, at the bottom I define our starting node to be node zero and then call the DFS method to do the exploration.

106) The DFS itself only has one argument, the current node we're at which I have conveniently named 'at'.

107) This method is recursive, so I check the base case which is whether we have already visited this node, is so we have no business here so we can return

108) Otherwise, let's visit this node by marking its visited status as true and exploring all its neighbors.

109) To explore all the neighbors of a node, reach into the adjacency list and pull out all the neighbors of this node and explore them depth first by looping over each and recursively call the DFS method.

110) That's what the DFS is in a nutshell.

111) Let's look at another simple use case for the DFS which I think will solidify your understanding. I want to discuss finding connected components in a graph.

112) First let's understand what we mean by connected component. Sometimes a graph is split into multiple disjoint components and it’s useful to be able to identify and count these components.

113) One way to identify these components might be to color them so we can tell them apart, but what does colouring nodes really mean for a computer?

114) Colouring nodes is equivalent to labeling each node in a component with the same id value. For example, every node in the purple component has an id of 1, and every node in the green component has an id of 4.

115) We can use a DFS to identify components. First, make sure all the nodes are labeled from [0, n) where n is the number of nodes.

116) The basic algorithm is to start a DFS at every node (except if it’s already been visited) and mark all reachable nodes as being part of the same component using the same id.

...

147) 




































