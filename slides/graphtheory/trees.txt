
Hello and welcome back, my name is William, and in today's video we're going to start tackling trees. In particular, we're going to look at what trees are and how we computationally store and represent trees.

Conceptually it's fair to say most people know what I mean when I say I'm working with a tree, or that something is structured as a tree. Below are four graphs, but one of them is not a tree, do you know which one?

Only the last graph is not a tree, but why is it not a tree?

It is because we define a tree as being an undirected graph with no cycles, and that's the key thing to remember. You can see that the rightmost graph has a cycle, and is therefore not a tree. However, there's an even easier way to check whether a graph is a tree or not.

Each tree has exactly n nodes and n-1 edges. If we count up all the nodes and edges of each graph you can see that all the trees have one less edge than the number of nodes, except for the rightmost graph which is not a tree.

We now know what trees are, but where do they appear in computer science and in the real world? Here are a few examples where you might encounter a tree structure:

  First is your computer's file system which consists of directories, subdirectories and files which is inherently a tree.

  Another place you see trees are in social hierarchies where you often see CEO's, kings, priests and generals at the top; and interns, servants, children and the lower class at the bottom.

  Trees are used to decompose source code and mathematical expressions into abstract syntax trees for easy evaluation. For example, the math expression you see on this slides can be broken down into a tree structure.

  Every webpage you visit can be throught of as a tree structure due to HTML's nested tag structure. This structure is used to tell your browser how to easily render the page.

  Another large application of trees is in game theory to model decisions and courses of action. On this slide is the famous prisoner's dilemma problem and it's four different outcomes.

  There are many many more applications of trees in computer science and in the real world, but we're not going to cover them all today. However, it's worth mentioning that in computer science the place you'll most often see trees are as part of data structures, many of which are listed below.

Now we need to talk about how we actually store and represent these undirected trees.

First, you will need to label the nodes of your tree by indexing it, preferably from 0 to n non-inclusive like the one on the left of this slide.

A simple way to store a tree is as an edge list, which is simply a list of undirected edges indicating which two nodes have an edge between them. The great thing about this representation is that it's super fast to iterate over and cheap to store.

The downside however, is that storing your tree as a list lacks the structure to efficiently query all the neighbors of a node.

This is why the adjacency list is usually a more popular representation to store an undirected tree. In this representation, you store a mapping between a node and all its neighbors.

For example, node 4 has the neighbors 1, 5 and 8 so in the adjacency list, node 4 maps to the list containing 1, 5 and 8 respectively.

You could also store a tree as an adjacency matrix of size n by n where having a 1 in a particular cell means that the nodes which corresponding to the row/column values have an edge between them.

However, in practice I would say to always avoid storing a tree as an adjacency matrix because it's a huge waste of space. You would not ever want to allocate n squared memory and only use roughly 2n of the matrix cells, it just doesn't make sense.


Alright, I can't keep talking about trees without mentioning rooted trees which are trees with a designated root node. I have highlighted the root node in orange, and most rooted trees as you'll notice have directed edges which point away from the root node, however it's also possible to have edges which point towards the root node, but those trees are much rarer in my experience.
Generally speaking, rooted trees are far easier to work with than undirected trees because they have a well defined structure and allow for recursive algorithm implementations.

Related to rooted trees are binary trees which are trees for which every node has at most two child nodes. The first two trees on this slide are binary trees, but the last one is not because it has a node with more than 2 child nodes.
You don't often see binary tree manifest themselves in the real world, for the most part binary trees are artificially created and integrated as part of data structures to guarantee efficient access and queries on data.

Now related to binary trees are binary search trees which are trees which satisfy the BST invariant. The BST invariant states that for every node x the values in the left subtree are less than or equal to x and that the values in the right subtree are greater than or equal to x. This nice little property enables you to quickly search through a tree and retrieve a certain value if it exists which is particularly handy. All the trees on this slide are BSTs except for the last one because 1 is not greater than or equal to 3.

It's often common to require uniqueness on the values of your tree so that you don't end up with duplicate values. To resolve this issue change the invariant to be strictly less than rather than less than or equal to.

Now let's talk about how to store these rooted trees. Rooted trees are naturally defined recursively in a top down manner.

In practice, you always maintain a pointer reference to the root node so that you can access the tree and its contents.

Then each node also has access to a list of all its children, which are also called child nodes. In this slides, the orange node is the current node we have a reference to and the purple nodes are its children. All the bottom or leaf nodes don't have any children.

It's also sometimes useful to maintain a pointer to a node’s parent node in case you need to traverse up the tree. This effectively makes the edges in the tree bidirectional. Again, if the current node is the orange node than the purple node in the case in the parent node.

However, maintaining an explicit reference to the parent node isn’t usually necessary because you can access a node’s parent on a recursive function's callback.


Another really neat way of storing a rooted tree if it is a binary tree is in a flattened array.

In the flattened array representation, each node has an assigned index position based on where it is in the tree. For example, the node with value 5 in orange is associated with the index 4 in the array. The tree is actually an array, the diagrams here is just a visual representation of what the tree would look like.

Similarly, this node with a value of 2 has an index of 6.

Even nodes which aren't currently present have an index because they can be
mapped back to a unique position in the "index tree" (gray tree).

In this format, the root node is always at index 0 in the array, so you always know where your starting point is. Another advantage of this format is that the child nodes of node i can be access relative to position i.

For example, if we're at position 2 in the array, we know that the left and right children of the node at index 2 is given by 2 times i plus 1 and 2 times i plus 2. Therefore the children of the node at index 2 can be found at positions 5 and 6. Reciprocally, this means if we have a node we know what the index of the parent node should be.

<trees in the wild>

  Do I want this section?

</trees in the wild>


<problem1>
  Alright, I want to start looking at how to write some useful tree algorithms.
  For this first problem, let's find the sum of all the leaf nodes of a tree.

  So given a tree such as this one we want to sum up all the bottom node values

  That would be all these nodes in red for a total of 9. If you're keen you can
  pause this video and give it a try.

  <press>

  Like all rooted tree problems we start with a reference to the root node. To solve this problem all we need to do is perform a tree traversal and identify leaf nodes while we do the traversal. It's pretty simple, watch how the animation does it.

  <do animation>

  At the end when we sum up all the values we can see that the sum of the leaf nodes should be 9. Now let's have a look at some pseudo-code

  The algorithm is pretty simple, but it may look strange at first if you haven't seen much recursive code.

  We call the leafSum function by passing in a reference to the root node as a starting point.

  We begin by handling the special case where the tree is empty and return zero in such a situation.

  The next thing we do is check if the current node is a leaf node, and if it is we return the value stored in the leaf node.

  The isLeaf method checks if a node is a leaf node by counting all its children. If the number of child nodes is zero then we know the node is a child node.

  If the node is node a leaf node then we iterate over all the children and all the leafSum method recursively summing over the return values. This ensures that we traverse the entire tree and properly accumulate values.

  Finally, once we have finished computing the total for this node and its subtree return the total.

  And that's all for summing up the leaf node values.
</problem1>

<problem2>
  Our second problem today is a classic problem in computer science which is to find the height of a binary tree. The height of a tree is defined as the number of edges from the root to the lowest leaf. So the leftmost tree has a height of zero because it has no edges, the middle tree has a height of 1 and the rightmost tree has a height of 3 because the longest path from the root to a leaf node is 3.

  To solve this problem we're going to break it down and define a new function h of x which returns the height of the subtree rooted at node x.
  This new function allows us to start thinking not only about the height of the tree as a whole but also the height of the subtrees within our tree which are going to help us find the overall height.

  For example, on this slide h of x has a value of 3, but h of b has a value of 2 and h of e has a value of zero.

  By themselves, leaf nodes such as node e don't have children, so they don’t add any additional height to the tree. So we can conclude that as a base case the height of any leaf node should be zero.

  Now, assuming node x is not a leaf node, we're able to formulate a recurrence relation for the height which is that the height of the subtree rooted at node x is the maximum of the height of x's left and right children plus one.

  Let's look at an example of how this works. Suppose we have this tree and we want to compute its height.

  So we start at the root

  and then we start traversing down the tree depth first

  If we encounter a leaf node we mark it as having a height of zero and return

  We can't compute the height of a node until we know the height of all its children, so we visit the right node.

  The right node is also a leaf node so it has a height of zero

  On the callback we have visited both children of the current node so we take the maximum heights of the left and the right children and add 1 for a total of 1.

  We just finished exploring the right half of the tree, now let's finished the left side. It doesn't matter which side you do first as long as you explore the whole tree while doing your DFS.

  <press>

  We found another leaf node so it gets a height of zero

  <press>

  <press>

  leaf node

  <press>

  leaf node

  take the max and add 1

  take the max and add 1 again

  finally compute the height of the final node by taking the max and adding 1

  And there you have it, how the find the height of a tree. Let's have a look at some pseudocode shall we.

  <pause and press>

  This is the treeHeight function, and it is responsible for computing the height of the tree. You would start by calling this function by passing in the tree's root node like we did for the leafSum function.

  The first thing we do is handle the empty tree case. The height of an empty tree is undefined so return -1.

  Next we check whether the current node is a leaf node by checking if both its left and right child are null and return zero. If either of them are not null then we know this node has more children and we need to keep digging down the tree.

  In the event we haven't found a leaf node, return the maximum height of the left subtree and the right subtree plus 1.

  Let's go back to the previous statement. What happens if we remove checking whether a node is a leaf node or not, would the algorithm still behave correctly? Pause the video and take a moment to think about this.

  Removing the leaf node check still makes the algorithm work correctly, but it changes the meaning of our base case. Instead of the base case checking for leaf nodes, it's now checking whether a node is null and returning -1. Returning -1 now not only checks for the empty tree case, but it also helps in correcting for the right height.

  Let's see what I mean by correcting for the right height. If our new base case is now checking for null nodes instead of the leaf nodes, then our tree one unit taller, so we need to correct for this.

  For the sake of being through, let's see how the height is calculated with this new base case.

  <press>

  <press>

  <press>

  <press>

  Once we reach a null node, return -1

  On the recursive callback recall that we always all +1

  <press>

  <press>

  <press>

  So when we add up the counts you see that we get the correct height of three. Effectively, returning -1 cancels itself with the leaf node's return value computing the correct number of edges for the height function.    
</problem2>



But why does this work? Suppose we want to find the height at node a, the root node, then we can do so by 




























